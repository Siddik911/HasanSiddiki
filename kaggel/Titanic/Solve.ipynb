{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "\n",
    "for dirname, _, filenames in os.walk(os.getcwd()):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirname, filename)\n",
    "        paths[filename] = full_path\n",
    "\n",
    "for a,b in paths.items():\n",
    "    print(f\"{a} {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92cc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in paths.items():\n",
    "    print(f\"{a} {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data.head()\n",
    "\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data.head()\n",
    "\n",
    "submission = pd.read_csv(\"gender_submission.csv\")\n",
    "\n",
    "# see if jack and rose is on the dataset ehehehe\n",
    "jack_rows = train_data[train_data[\"Name\"].str.contains(\"jack\", case=False, na=False)]\n",
    "rose_rows = train_data[train_data[\"Name\"].str.contains(\"rose\", case=False, na=False)]\n",
    "\n",
    "jack_rows[[\"PassengerId\", \"Name\"]]\n",
    "print()\n",
    "rose_rows[[\"PassengerId\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80574ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.columns)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_passengers = train_data[train_data['PassengerId'] % 2 == 0]\n",
    "odd_passengers = train_data[train_data['PassengerId'] % 2 == 1]\n",
    "\n",
    "total_even = len(even_passengers)\n",
    "total_odd = len(odd_passengers)\n",
    "\n",
    "print(f\"Total passengers with EVEN PassengerId: {total_even}\")\n",
    "print(f\"Total passengers with ODD PassengerId: {total_odd}\")\n",
    "print(f\"Total passengers: {total_even + total_odd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad77f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "print(\"Training Data Shape:\", train_data.shape)\n",
    "print(\"\\nTraining Data Info:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"\\nSurvival Rate:\")\n",
    "print(train_data['Survived'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival by different features\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Survival by Sex\n",
    "sns.countplot(data=train_data, x='Sex', hue='Survived', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Survival by Sex')\n",
    "\n",
    "# Survival by Pclass\n",
    "sns.countplot(data=train_data, x='Pclass', hue='Survived', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Survival by Passenger Class')\n",
    "\n",
    "# Age distribution\n",
    "train_data[train_data['Survived']==1]['Age'].hist(bins=30, alpha=0.5, label='Survived', ax=axes[1, 0])\n",
    "train_data[train_data['Survived']==0]['Age'].hist(bins=30, alpha=0.5, label='Not Survived', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Age Distribution by Survival')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Survival by Embarked\n",
    "sns.countplot(data=train_data, x='Embarked', hue='Survived', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Survival by Embarked Port')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Function\n",
    "def preprocess_data(df, is_train=True):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Fill missing Age with median\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    \n",
    "    # Fill missing Embarked with mode\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Fill missing Fare with median (for test data)\n",
    "    if 'Fare' in data.columns:\n",
    "        data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    \n",
    "    # Create new features\n",
    "    # Family size\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    \n",
    "    # IsAlone\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # Extract Title from Name\n",
    "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Simplify titles\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', \n",
    "                                            'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Create Age bands\n",
    "    data['AgeBand'] = pd.cut(data['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "    labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    \n",
    "    # Create Fare bands\n",
    "    data['FareBand'] = pd.qcut(data['Fare'], 4, labels=['Low', 'Medium', 'High', 'VeryHigh'], duplicates='drop')\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Preprocess both datasets\n",
    "train_processed = preprocess_data(train_data, is_train=True)\n",
    "test_processed = preprocess_data(test_data, is_train=False)\n",
    "\n",
    "print(\"Processed Training Data:\")\n",
    "print(train_processed.head())\n",
    "print(\"\\nProcessed columns:\", train_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine train and test for consistent encoding\n",
    "combine = [train_processed, test_processed]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "categorical_features = ['Sex', 'Embarked', 'Title', 'AgeBand', 'FareBand']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to ensure consistent encoding\n",
    "    all_values = pd.concat([train_processed[feature], test_processed[feature]]).astype(str)\n",
    "    le.fit(all_values)\n",
    "    \n",
    "    train_processed[feature] = le.transform(train_processed[feature].astype(str))\n",
    "    test_processed[feature] = le.transform(test_processed[feature].astype(str))\n",
    "    \n",
    "    label_encoders[feature] = le\n",
    "\n",
    "print(\"Encoded Training Data:\")\n",
    "print(train_processed.head())\n",
    "print(\"\\nData types:\")\n",
    "print(train_processed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Separate features and target\n",
    "X = train_processed.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = train_processed['Survived']\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"\\nFeatures used:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "print(f\"\\nCross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daad8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature')\n",
    "plt.title('Feature Importance in Random Forest Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all training data\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X, y)\n",
    "print(\"Final model trained on all training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "X_test = test_processed.drop(['PassengerId'], axis=1)\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "print(\"Submission DataFrame:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\nTotal predictions: {len(submission_df)}\")\n",
    "print(f\"Predicted survivors: {predictions.sum()}\")\n",
    "print(f\"Predicted non-survivors: {len(predictions) - predictions.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission file\n",
    "submission_df.to_csv('titanic_submission.csv', index=False)\n",
    "print(\"Submission file saved as 'titanic_submission.csv'\")\n",
    "print(\"\\nTo submit:\")\n",
    "print(\"1. Go to https://www.kaggle.com/c/titanic/submit\")\n",
    "print(\"2. Upload the 'titanic_submission.csv' file\")\n",
    "print(\"3. Add a description and submit!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
